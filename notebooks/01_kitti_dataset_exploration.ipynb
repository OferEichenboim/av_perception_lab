{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780fcdc2",
   "metadata": {},
   "source": [
    "# This notebook explores the KITTI 2D object detection dataset. #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6c822",
   "metadata": {},
   "source": [
    "### Imports  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492df3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard packages\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "#from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bdb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to Python path so we can import from datasets\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "sys.path.append(ROOT)\n",
    "print(\"Project root: \",ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f87017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import self packages\n",
    "from datasets.kitti.object2d.parser import Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce8719",
   "metadata": {},
   "source": [
    "### Display few examples of the Dataset ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add dataset image path\n",
    "dataset_image_path = Path(\"../datasets/kitti/object2d/training/image_2/\")\n",
    "dataset_label_path = Path(\"../datasets/kitti/object2d/training/label_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c52211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display images from the dataset\n",
    "images = [\"000000.png\",\"000010.png\",\"000020.png\",\"000030.png\",\"000040.png\",\"000050.png\"] \n",
    "images = [dataset_image_path /path for path in images]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(images):\n",
    "    img = np.array(Image.open(img_path))\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(img_path.name)\n",
    "    axes[idx].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display parsed labels\n",
    "label_1_file = \"../datasets/kitti/object2d/training/label_2/000000.txt\"\n",
    "label_2_file = \"../datasets/kitti/object2d/training/label_2/000010.txt\"\n",
    "label_1_parser = Parser(label_1_file)\n",
    "label_2_parser = Parser(label_2_file)\n",
    "label_1_list = label_1_parser.parse_results\n",
    "label_2_list = label_2_parser.parse_results\n",
    "\n",
    "print(\"label_1 after parsing:\\n\")\n",
    "for item in label_1_list:\n",
    "    print(item)\n",
    "print(\"\\nlabel_2 after parsing:\\n\")\n",
    "for item in label_2_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612ec6d",
   "metadata": {},
   "source": [
    "### Display bounding boxes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6fe87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualizations.draw_boxes import Box,Box_kitti_obj2d\n",
    "\n",
    "#get images\n",
    "img1 = images[0]\n",
    "img2 = images[1]\n",
    "\n",
    "#get labels\n",
    "label1 = label_1_list[0]\n",
    "label2 = label_2_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#generate box images\n",
    "box1_image = Box_kitti_obj2d(img1,label1)\n",
    "box2_image = Box_kitti_obj2d(img2,label2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "fig, axes = plt.subplots(1, 2, figsize=(30, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "box_images = [box1_image,box2_image]\n",
    "for idx, img in enumerate(box_images):\n",
    "    axes[idx].imshow(img.draw())\n",
    "    axes[idx].set_title(img.type+\" (single label)\", fontsize = 30)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d1787",
   "metadata": {},
   "source": [
    "### Display DontCare class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bda93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display DontCare type\n",
    "dontcare_labels = label_2_list[-4:]\n",
    "\n",
    "#generate box images\n",
    "box_images = [Box_kitti_obj2d(img2,label) for label in dontcare_labels]\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(30, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img in enumerate(box_images):\n",
    "    axes[idx].imshow(img.draw())\n",
    "    axes[idx].set_title(img.type, fontsize = 30)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf5a74",
   "metadata": {},
   "source": [
    "### Check dataset attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a global list of conclusions\n",
    "conclusions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040dbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataset\n",
    "data_path_img = Path(os.path.join(ROOT,\"datasets\",\"kitti\",\"object2d\",\"training\",\"image_2\"))\n",
    "data_path_lab = Path(os.path.join(ROOT,\"datasets\",\"kitti\",\"object2d\",\"training\",\"label_2\"))\n",
    "\n",
    "image_paths = [img for img in data_path_img.iterdir() if img.is_file()]\n",
    "label_paths = [label for label in data_path_lab.iterdir() if label.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check identical resolution to all images\n",
    "from collections import Counter\n",
    "shapes = Counter()\n",
    "\n",
    "for img_path in image_paths:\n",
    "    with Image.open(img_path) as im:\n",
    "        shapes[(im.height, im.width, len(im.getbands()))] += 1\n",
    "\n",
    "if len(shapes)==1:\n",
    "    conc = \"All images are with the same shape\"\n",
    "else:\n",
    "    conc = \"There are images of different shapes\"\n",
    "conclusions.append(conc)\n",
    "print(conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed403926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display resolution distribution\n",
    "\n",
    "resolutions = [str(k) for k in shapes.keys()]\n",
    "counts = list(shapes.values())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(resolutions, counts)\n",
    "plt.xlabel(\"Image resolution (H, W, C)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Image resolution distribution\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5050ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all images\\labels of the same type\n",
    "\n",
    "img_types = Counter()\n",
    "for img_p in image_paths:\n",
    "    type = img_p.suffix\n",
    "    img_types[type]+=1\n",
    "\n",
    "label_types = Counter()\n",
    "for lab_p in label_paths:\n",
    "    type = lab_p.suffix\n",
    "    label_types[type]+=1\n",
    "\n",
    "if len(img_types)>1:\n",
    "    conc_img = f\"There are iamges of different types: {img_types} \" \n",
    "else:\n",
    "    conc_img = f\"There is a single image type: {img_types}\"\n",
    "conclusions.append(f\"{conc_img}\")\n",
    "\n",
    "if len(label_types)>1:\n",
    "    conc_lbl = f\"There are label files of different types: {label_types} \" \n",
    "else:\n",
    "    conc_lbl = f\"There is a single label files type: {label_types}\"\n",
    "\n",
    "conclusions.append(f\"{conc_lbl}\")\n",
    "\n",
    "print(f\"image types: {img_types}\")\n",
    "print(f\"label types: {label_types}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check label-image couples matching\n",
    "mismatch_counter = 0\n",
    "for i in range(len(image_paths)):\n",
    "    img_name = image_paths[i].stem\n",
    "    label_name = label_paths[i].stem\n",
    "    if img_name!=label_name:\n",
    "        print(f\"image name: {img_name} | label name: {label_name}\")\n",
    "        mismatch_counter=1\n",
    "if not mismatch_counter:\n",
    "    conc = \"All image-label couples were found with no errors.\"\n",
    "else:\n",
    "    conc = \"There are image-label couples error (mismatch or order)\"\n",
    "    \n",
    "print(conc)\n",
    "conclusions.append(conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all bounding boxes are within range\n",
    "bbox_dimension_flag = 0\n",
    "\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    with Image.open(img_path) as im:\n",
    "        img_h,img_w = im.height, im.width\n",
    "    for label in label_list:\n",
    "        lx,ly,rx,ry = label.bbox.lx, label.bbox.ly, label.bbox.rx, label.bbox.ry\n",
    "        if lx > img_w or rx > img_w or ly > img_h or ry > img_h:\n",
    "            conc = \"There are bounding boxes in labels that exeeds image dimension.\"\n",
    "            print(\"The following bbox dimension exceeds image dimension\")\n",
    "            print(f\"image dim: {img_w,img_h} | {label.bbox.start_point} -> {label.bbox.end_point} \")\n",
    "            bbox_dimension_flag = 1\n",
    "            \n",
    "if bbox_dimension_flag == 0:\n",
    "    conc = \"All bounding boxes are within image range\"\n",
    "conclusions.append(conc)\n",
    "print(conc)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e130c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check classes distribution - numerical and bar plot\n",
    "class_counter = Counter()\n",
    "\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        class_counter[label.type] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b441a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_counter)\n",
    "\n",
    "class_resolutions = [str(k) for k in class_counter.keys()]\n",
    "class_counts = list(class_counter.values())\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_resolutions, class_counts)\n",
    "plt.xlabel(\"Class type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Classes distribution\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = f\"There are {len(class_counter)} classes on the dataset with max class {class_counter.most_common(1)} and min class {class_counter.most_common()[-1]}\"\n",
    "conclusions.append(conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8d3033",
   "metadata": {},
   "source": [
    "### Check bounding box statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fde0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area distribution\n",
    "#Aspect ratio distribution\n",
    "hw_dict = {}\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        if label.type not in hw_dict.keys():\n",
    "            hw_dict[label.type] = []\n",
    "        hw_dict[label.type] += [(round(label.bbox.ry - label.bbox.ly,2), round(label.bbox.rx - label.bbox.lx,2))] #heigh width tuple\n",
    "    \n",
    "#convert to HxW array of N rows\n",
    "for key in hw_dict.keys():\n",
    "    box_arr = np.asarray(hw_dict[key], dtype=np.float32)\n",
    "    hw_dict[key] = box_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hw_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "from visualizations.bbox_statistics import plot_bbox_hw_distribution\n",
    "\n",
    "fig, axes = plt.subplots(3, 3,figsize=(20, 20),sharex=True,sharey=True)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (cls_name, hw) in enumerate(hw_dict.items()):\n",
    "    plot_bbox_hw_distribution(\n",
    "        hw,\n",
    "        method='hexbin',\n",
    "        log_scale=True,\n",
    "        ax=axes[idx],\n",
    "        title=f\"{cls_name} (n={len(hw)})\"\n",
    "    )\n",
    "\n",
    "# Remove unused axes (safety)\n",
    "# for j in range(len(hw_dict), len(axes)):\n",
    "#     fig.delaxes(axes[j])\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Bounding Box Height Ã— Width Distribution per Class\",\n",
    "    fontsize=16\n",
    ")\n",
    "\n",
    "fig.supxlabel(\"Width (normalized)\")\n",
    "fig.supylabel(\"Height (normalized)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = \"Consider bounding box area distribution as a factor with small effect to be considered.\"\n",
    "conclusions.append(conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0846c3",
   "metadata": {},
   "source": [
    "### Occlusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Occlusions\n",
    "occlusion_levels = set()\n",
    "occlusion_samples = {}\n",
    "occlusion_num = 4\n",
    "\n",
    "#loop over all images to find occlueded labels\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        occlusion_levels.add(label.occluded)\n",
    "        if label.occluded not in occlusion_samples.keys():\n",
    "            occlusion_samples[label.occluded] = []\n",
    "        elif len(occlusion_samples[label.occluded])<occlusion_num: \n",
    "            #val = [label_paths[i].stem, i, label.type, label.bbox]\n",
    "            val = [label_paths[i].stem ,label.label_dict]\n",
    "            occlusion_samples[label.occluded].append(val)\n",
    "            break\n",
    "            \n",
    "print(\"Occlusion levels: \",occlusion_levels)                \n",
    "print(\"Occlusion samples:\\n\",occlusion_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3480a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get full image path\n",
    "for lvl in occlusion_levels:\n",
    "    for sample in occlusion_samples[lvl]:\n",
    "        sample_name = sample[0]+\".png\"\n",
    "        sample[0] = dataset_image_path / Path(sample_name)\n",
    "\n",
    "print(occlusion_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7409f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display Occluded images\n",
    "#generate box images\n",
    "print(dir(Box_kitti_obj2d))\n",
    "for lvl in occlusion_levels:\n",
    "    box_images = [Box_kitti_obj2d(sample[0], sample[1]) for sample in occlusion_samples[lvl]]\n",
    "\n",
    "    # Display\n",
    "    rows = int(len(occlusion_samples[lvl])/2)\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(30, 20))\n",
    "    axes = axes.flatten()\n",
    "    fig.suptitle(f\"Occlusion level: {lvl}\", fontsize=40)\n",
    "    for idx, img in enumerate(box_images):\n",
    "        axes[idx].imshow(img.draw())\n",
    "        axes[idx].set_title(img.type, fontsize = 30)\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ddfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if occlusion_level = -1 is only for DontCare label type\n",
    "dontcare_only = True\n",
    "\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        if label.occluded == -1 and label.type != \"DontCare\":\n",
    "           dontcare_only = False \n",
    "           conc = \"all classes can have an occluded level = -1\"\n",
    "\n",
    "if dontcare_only ==True:\n",
    "    conc = \"Only DontCare class can have an occluded level = -1\"\n",
    "    print(conc)\n",
    "conclusions.append(conc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad8604",
   "metadata": {},
   "source": [
    "### Truncation investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3117a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all truncated values\n",
    "truncation_counter = Counter()\n",
    "\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        truncation_val = label.truncated\n",
    "        truncation_counter[truncation_val]+=1\n",
    "\n",
    "most_common_truncation = truncation_counter.most_common(4)\n",
    "conc = f\"The most common truncations: {most_common_truncation}\"\n",
    "conclusions.append(conc)\n",
    "print(conc)\n",
    "\n",
    "trunc_sorted = sorted(truncation_counter.items())\n",
    "truncation = dict(trunc_sorted)\n",
    "print(truncation)\n",
    "#check corelation between truncation and occlusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if truncation = -1 is only for dontcare\n",
    "dontcare_only_truncated = True\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        if label.truncated == -1.0 and label.type.lower() != \"dontcare\":\n",
    "            dontcare_only_truncated= False\n",
    "            print(label.type)\n",
    "\n",
    "if dontcare_only_truncated:\n",
    "    conc = \"Only dontcare class gave truncated = -1\"\n",
    "    conclusions.append(conc)\n",
    "    print(conc)\n",
    "    most_common_truncation = truncation_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display truncation examples\n",
    "common_truncation_levels = [val for (val,count) in most_common_truncation if val!=-1]\n",
    "used = []\n",
    "unique_samples = 0\n",
    "truncation_samples = []\n",
    "\n",
    "for i in range(len(label_paths)):\n",
    "    label_list = Parser(label_paths[i]).label_list\n",
    "    for label in label_list:\n",
    "        if label.truncated in common_truncation_levels and label.truncated not in used:     \n",
    "            truncation_samples.append([label_paths[i],label])\n",
    "            used.append(label.truncated)\n",
    "        elif unique_samples<4:\n",
    "            if label.truncated >0.2 and label.truncated<0.8:\n",
    "                truncation_samples.append([label_paths[i],label])\n",
    "                unique_samples+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation_pairs = []\n",
    "for label_path,label in truncation_samples:\n",
    "    label_name = label_path.stem\n",
    "    sample_name = label_name+\".png\"\n",
    "    img_path = dataset_image_path / Path(sample_name)\n",
    "    truncation_pairs.append([img_path,label])\n",
    "\n",
    "\n",
    "box_truncated_images = [Box_kitti_obj2d(img, label.label_dict) for [img,label] in truncation_pairs]\n",
    "\n",
    "# Display\n",
    "rows = int(len(box_truncated_images)/2)\n",
    "fig, axes = plt.subplots(rows, 2, figsize=(30, 20))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle(f\"Truncation samples\", fontsize=40)\n",
    "for idx, img in enumerate(box_truncated_images):\n",
    "    axes[idx].imshow(img.draw())\n",
    "    axes[idx].set_title(f\"{img.type}, truncation = {truncation_samples[idx][1].truncated}\", fontsize = 30)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d74447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Conclusions:\")\n",
    "for conc in conclusions:\n",
    "    print(conc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
